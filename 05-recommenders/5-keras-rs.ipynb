{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dEaVsqSgNyQ"
      },
      "source": [
        "# NOTEBOOK 5 KerasRS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f-reQ11gbLB"
      },
      "source": [
        "[Recommending movies: retrieval](https://keras.io/keras_rs/examples/basic_retrieval/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA00wBE2Ntdm"
      },
      "source": [
        "### Import KerasRS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yzAaM85Z12D"
      },
      "outputs": [],
      "source": [
        "!pip install -q keras-rs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3oYt3R6Nr9l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # `\"tensorflow\"`/`\"torch\"`\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf  # Needed for the dataset\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import keras_rs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCxQ1CZcO2wh"
      },
      "source": [
        "### Read the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-mxBYjdO5m7"
      },
      "outputs": [],
      "source": [
        "# Ratings data with user and movie data.\n",
        "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
        "# Features of all the available movies.\n",
        "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for data in ratings.take(1).as_numpy_iterator():\n",
        "    print(str(data).replace(\", '\", \",\\n '\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9I1VTEjHzpfX"
      },
      "outputs": [],
      "source": [
        "users_count = (\n",
        "    ratings.map(lambda x: tf.strings.to_number(x[\"user_id\"], out_type=tf.int32))\n",
        "    .reduce(tf.constant(0, tf.int32), tf.maximum)\n",
        "    .numpy()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for data in movies.take(1).as_numpy_iterator():\n",
        "    print(str(data).replace(\", '\", \",\\n '\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "movies_count = movies.cardinality().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_rating(x):\n",
        "    return (\n",
        "        # Input is the user IDs\n",
        "        tf.strings.to_number(x[\"user_id\"], out_type=tf.int32),\n",
        "        # Labels are movie IDs + ratings between 0 and 1.\n",
        "        {\n",
        "            \"movie_id\": tf.strings.to_number(x[\"movie_id\"], out_type=tf.int32),\n",
        "            \"rating\": (x[\"user_rating\"] - 1.0) / 4.0,\n",
        "        },\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shuffled_ratings = ratings.map(preprocess_rating).shuffle(\n",
        "    100_000, seed=42, reshuffle_each_iteration=False\n",
        ")\n",
        "train_ratings = shuffled_ratings.take(80_000).batch(1000).cache()\n",
        "test_ratings = shuffled_ratings.skip(80_000).take(20_000).batch(1000).cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lrch6rVBOB9Q"
      },
      "source": [
        "### Define a model\n",
        "\n",
        "Notad que definimos el tamaño de los embeddings en 32 (cuanto más grande, más preciso).\n",
        "\n",
        "El proceso de Retrieval usa `keras_rs.layers.BruteForceRetrieval` y devuelve los top10. \n",
        "\n",
        "Durante el entrenamiento, no hago retrieval, sólo devuelvo user_embeddings\n",
        "\n",
        "Durante la predicción hago retrieval, y devuelvo los top10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5dNbDZwOIHR"
      },
      "outputs": [],
      "source": [
        "class RetrievalModel(keras.Model):\n",
        "    \"\"\"Create the retrieval model with the provided parameters.\n",
        "\n",
        "    Args:\n",
        "      num_users: Number of entries in the user embedding table.\n",
        "      num_candidates: Number of entries in the candidate embedding table.\n",
        "      embedding_dimension: Output dimension for user and movie embedding tables.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_users,\n",
        "        num_candidates,\n",
        "        embedding_dimension=32,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        # Our query tower, simply an embedding table.\n",
        "        self.user_embedding = keras.layers.Embedding(num_users, embedding_dimension)\n",
        "        # Our candidate tower, simply an embedding table.\n",
        "        self.candidate_embedding = keras.layers.Embedding(\n",
        "            num_candidates, embedding_dimension\n",
        "        )\n",
        "        # The layer that performs the retrieval.\n",
        "        self.retrieval = keras_rs.layers.BruteForceRetrieval(k=10, return_scores=False)\n",
        "        self.loss_fn = keras.losses.MeanSquaredError()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.user_embedding.build(input_shape)\n",
        "        self.candidate_embedding.build(input_shape)\n",
        "        # In this case, the candidates are directly the movie embeddings.\n",
        "        # We take a shortcut and directly reuse the variable.\n",
        "        self.retrieval.candidate_embeddings = self.candidate_embedding.embeddings\n",
        "        self.retrieval.build(input_shape)\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        user_embeddings = self.user_embedding(inputs)\n",
        "        result = {\n",
        "            \"user_embeddings\": user_embeddings,\n",
        "        }\n",
        "        if not training:\n",
        "            # Skip the retrieval of top movies during training as the\n",
        "            # predictions are not used.\n",
        "            result[\"predictions\"] = self.retrieval(user_embeddings)\n",
        "        return result\n",
        "\n",
        "    def compute_loss(self, x, y, y_pred, sample_weight, training=True):\n",
        "        candidate_id, rating = y[\"movie_id\"], y[\"rating\"]\n",
        "        user_embeddings = y_pred[\"user_embeddings\"]\n",
        "        candidate_embeddings = self.candidate_embedding(candidate_id)\n",
        "\n",
        "        labels = keras.ops.expand_dims(rating, -1)\n",
        "        # Compute the affinity score by multiplying the two embeddings.\n",
        "        scores = keras.ops.sum(\n",
        "            keras.ops.multiply(user_embeddings, candidate_embeddings),\n",
        "            axis=1,\n",
        "            keepdims=True,\n",
        "        )\n",
        "        return self.loss_fn(labels, scores, sample_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMV0HpzmJGWk"
      },
      "source": [
        "\n",
        "### Fit and evaluate it.\n",
        "\n",
        "Create the model, train it, and generate predictions:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2tQDhqkOKf1"
      },
      "outputs": [],
      "source": [
        "# TODO: Define mdoel and train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Making predictions\n",
        "\n",
        "Llama por debajo a `BruceForceRetrieval'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "movie_id_to_movie_title = {\n",
        "    int(x[\"movie_id\"]): x[\"movie_title\"] for x in movies.as_numpy_iterator()\n",
        "}\n",
        "movie_id_to_movie_title[0] = \"\"  # Because id 0 is not in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_id = 42\n",
        "predictions = model.predict(keras.ops.convert_to_tensor([user_id]))\n",
        "predictions = keras.ops.convert_to_numpy(predictions[\"predictions\"])\n",
        "\n",
        "print(f\"Recommended movies for user {user_id}:\")\n",
        "for movie_id in predictions[0]:\n",
        "    print(movie_id_to_movie_title[movie_id])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "quickstart.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
