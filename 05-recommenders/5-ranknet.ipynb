{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTEBOOK 5 RankNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture with Keras functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, activations, losses, Model, Input\n",
    "from tensorflow.nn import leaky_relu\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from tensorflow.keras.utils import plot_model, Progbar\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# model architecture\n",
    "class RankNet(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense = [layers.Dense(16, activation=leaky_relu), layers.Dense(8, activation=leaky_relu)]\n",
    "        self.o = layers.Dense(1, activation='linear')\n",
    "        self.oi_minus_oj = layers.Subtract()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        xi, xj = inputs\n",
    "        densei = self.dense[0](xi)\n",
    "        densej = self.dense[0](xj)\n",
    "        for dense in self.dense[1:]:\n",
    "            densei = dense(densei)\n",
    "            densej = dense(densej)\n",
    "        oi = self.o(densei)\n",
    "        oj= self.o(densej)\n",
    "        oij = self.oi_minus_oj([oi, oj])\n",
    "        output = layers.Activation('sigmoid')(oij)\n",
    "        return output\n",
    "    \n",
    "    def build_graph(self):\n",
    "        x = [Input(shape=(10)), Input(shape=(10))]\n",
    "        return Model(inputs=x, outputs=self.call(x))\n",
    "\n",
    "# visualize model architecture\n",
    "plot_model(RankNet().build_graph(), show_shapes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "nb_query = 20\n",
    "query = np.array([i+1 for i in range(nb_query) for x in range(int(np.ceil(np.abs(np.random.normal(0,scale=15))+2)))])\n",
    "doc_features = np.random.random((len(query), 10))\n",
    "doc_scores = np.random.randint(5, size=len(query)).astype(np.float32)\n",
    "\n",
    "\n",
    "# put data into pairs\n",
    "xi = []\n",
    "xj = []\n",
    "pij = []\n",
    "pair_id = []\n",
    "pair_query_id = []\n",
    "for q in np.unique(query):\n",
    "    query_idx = np.where(query == q)[0]\n",
    "    for pair_idx in combinations(query_idx, 2):\n",
    "        pair_query_id.append(q)\n",
    "        \n",
    "        pair_id.append(pair_idx)\n",
    "        i = pair_idx[0]\n",
    "        j = pair_idx[1]\n",
    "        xi.append(doc_features[i])\n",
    "        xj.append(doc_features[j])\n",
    "        \n",
    "        if doc_scores[i] == doc_scores[j]:\n",
    "            _pij = 0.5\n",
    "        elif doc_scores[i] > doc_scores[j]:\n",
    "            _pij = 1\n",
    "        else: \n",
    "            _pij = 0\n",
    "        pij.append(_pij)\n",
    "        \n",
    "xi = np.array(xi)\n",
    "xj = np.array(xj)\n",
    "pij = np.array(pij)\n",
    "pair_query_id = np.array(pair_query_id)\n",
    "print(pair_query_id)\n",
    "\n",
    "xi_train, xi_test, xj_train, xj_test, pij_train, pij_test, pair_id_train, pair_id_test = train_test_split(\n",
    "    xi, xj, pij, pair_id, test_size=0.2, stratify=pair_query_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model using compile and fit\n",
    "ranknet = RankNet()\n",
    "ranknet.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "history = ranknet.fit([xi_train, xj_train], pij_train, epochs=50, batch_size=1, validation_data=([xi_test, xj_test], pij_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot loss metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting loss\n",
    "def plot_metrics(train_metric, val_metric=None, metric_name=None, title=None, ylim=5):\n",
    "    plt.title(title)\n",
    "    plt.ylim(0,ylim)\n",
    "    plt.plot(train_metric,color='blue',label=metric_name)\n",
    "    if val_metric is not None: plt.plot(val_metric,color='green',label='val_' + metric_name)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "# plot loss history\n",
    "plot_metrics(history.history['loss'], history.history['val_loss'], \"Loss\", \"Loss\", ylim=1.0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
